{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 172, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/adity/mcp-project/Nextjs-MCP-Chat/lib/mcp-client/index.ts"],"sourcesContent":["import { OpenAI } from \"openai\";\r\nimport dotenv from \"dotenv\";\r\nimport { McpClient, StdioTransport } from \"@mcp/client\";\r\nimport { McpMessage } from \"@mcp/protocol\";\r\nimport { AI } from \"@/app/actions\";\r\nimport path from \"path\";\r\nimport os from \"os\";\r\n\r\ndotenv.config();\r\n\r\nconst OPENAI_API_KEY = process.env.OPENAI_API_KEY;\r\nconst MODEL_NAME = \"gpt-4o-mini\";\r\n\r\nif (!OPENAI_API_KEY) throw new Error(\"OPENAI_API_KEY is not set\");\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: OPENAI_API_KEY,\r\n});\r\n\r\nlet mcp: McpClient | null = null;\r\nlet tools: any[] = [];\r\n\r\nlet connected = false;\r\n\r\nexport async function initMCP(serverScriptPath: string) {\r\n  if (mcp) {\r\n    return;\r\n  }\r\n\r\n  mcp = new McpClient({\r\n    isServer: false,\r\n    logger: console,\r\n  });\r\n\r\n  console.log(serverScriptPath);\r\n\r\n  const transport = new StdioTransport({\r\n    command: \"npx\",\r\n    args: [\"tsx\", serverScriptPath, os.homedir()],\r\n  });\r\n\r\n  mcp.connect(transport);\r\n\r\n  const toolsResult = await mcp.listTools();\r\n\r\n  tools = toolsResult.tools.map((tool) => ({\r\n    type: \"function\",\r\n    function: {\r\n      name: tool.name,\r\n      description: tool.description,\r\n      parameters: tool.inputSchema,\r\n    },\r\n  }));\r\n\r\n  connected = true;\r\n  console.log(\r\n    \"MCP Connected with tools:\",\r\n    tools.map((t) => t.function.name),\r\n  );\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nexport async function executeToolCall(toolCall: any) {\r\n  const toolName = toolCall.function.name;\r\n  const toolArgs = JSON.parse(toolCall.function.arguments || \"{}\");\r\n\r\n  if (!mcp) {\r\n    throw new Error(\"MCP client not initialized\");\r\n  }\r\n\r\n  const result = await mcp.callTool({\r\n    name: toolName,\r\n    arguments: toolArgs,\r\n  });\r\n\r\n  return {\r\n    id: toolCall.id,\r\n    name: toolName,\r\n    arguments: toolArgs,\r\n    result: result.content,\r\n  };\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nexport async function processQuery(messagesInput: any[]) {\r\n  const messages: OpenAI.ChatCompletionMessageParam[] = [\r\n    {\r\n      role: \"system\",\r\n      content: \"You are a helpful assistant that can use tools.\",\r\n    },\r\n    ...messagesInput,\r\n  ];\r\n\r\n  const response = await openai.chat.completions.create({\r\n    model: MODEL_NAME,\r\n    max_tokens: 1000,\r\n    messages,\r\n    tools,\r\n  });\r\n\r\n  const replyMessage = response.choices[0].message;\r\n  const toolCalls = replyMessage.tool_calls || [];\r\n\r\n  if (toolCalls.length > 0) {\r\n    const toolResponses = [];\r\n\r\n    for (const toolCall of toolCalls) {\r\n      const toolResponse = await executeToolCall(toolCall);\r\n      toolResponses.push(toolResponse);\r\n\r\n      messages.push({\r\n        role: \"assistant\",\r\n        content: null,\r\n        tool_calls: [toolCall],\r\n      });\r\n\r\n      messages.push({\r\n        role: \"tool\",\r\n        content: toolResponse.result as string,\r\n        tool_call_id: toolCall.id,\r\n      });\r\n    }\r\n\r\n    const followUp = await openai.chat.completions.create({\r\n      model: MODEL_NAME,\r\n      messages,\r\n    });\r\n\r\n    return {\r\n      reply: followUp.choices[0].message.content || \"\",\r\n      toolCalls,\r\n      toolResponses,\r\n    };\r\n  }\r\n\r\n  return {\r\n    reply: replyMessage.content || \"\",\r\n    toolCalls: [],\r\n    toolResponses: [],\r\n  };\r\n}\r\n"],"names":[],"mappings":";;;;;AAAA;AACA;;;;;;AAKA;;;;;AAEA,uIAAA,CAAA,UAAM,CAAC,MAAM;AAEb,MAAM,iBAAiB,QAAQ,GAAG,CAAC,cAAc;AACjD,MAAM,aAAa;AAEnB,IAAI,CAAC,gBAAgB,MAAM,IAAI,MAAM;AAErC,MAAM,SAAS,IAAI,kJAAA,CAAA,SAAM,CAAC;IACxB,QAAQ;AACV;AAEA,IAAI,MAAwB;AAC5B,IAAI,QAAe,EAAE;AAErB,IAAI,YAAY;AAET,eAAe,QAAQ,gBAAwB;IACpD,IAAI,KAAK;QACP;IACF;IAEA,MAAM,IAAI,UAAU;QAClB,UAAU;QACV,QAAQ;IACV;IAEA,QAAQ,GAAG,CAAC;IAEZ,MAAM,YAAY,IAAI,eAAe;QACnC,SAAS;QACT,MAAM;YAAC;YAAO;YAAkB,6FAAA,CAAA,UAAE,CAAC,OAAO;SAAG;IAC/C;IAEA,IAAI,OAAO,CAAC;IAEZ,MAAM,cAAc,MAAM,IAAI,SAAS;IAEvC,QAAQ,YAAY,KAAK,CAAC,GAAG,CAAC,CAAC,OAAS,CAAC;YACvC,MAAM;YACN,UAAU;gBACR,MAAM,KAAK,IAAI;gBACf,aAAa,KAAK,WAAW;gBAC7B,YAAY,KAAK,WAAW;YAC9B;QACF,CAAC;IAED,YAAY;IACZ,QAAQ,GAAG,CACT,6BACA,MAAM,GAAG,CAAC,CAAC,IAAM,EAAE,QAAQ,CAAC,IAAI;AAEpC;AAGO,eAAe,gBAAgB,QAAa;IACjD,MAAM,WAAW,SAAS,QAAQ,CAAC,IAAI;IACvC,MAAM,WAAW,KAAK,KAAK,CAAC,SAAS,QAAQ,CAAC,SAAS,IAAI;IAE3D,IAAI,CAAC,KAAK;QACR,MAAM,IAAI,MAAM;IAClB;IAEA,MAAM,SAAS,MAAM,IAAI,QAAQ,CAAC;QAChC,MAAM;QACN,WAAW;IACb;IAEA,OAAO;QACL,IAAI,SAAS,EAAE;QACf,MAAM;QACN,WAAW;QACX,QAAQ,OAAO,OAAO;IACxB;AACF;AAGO,eAAe,aAAa,aAAoB;IACrD,MAAM,WAAgD;QACpD;YACE,MAAM;YACN,SAAS;QACX;WACG;KACJ;IAED,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;QACpD,OAAO;QACP,YAAY;QACZ;QACA;IACF;IAEA,MAAM,eAAe,SAAS,OAAO,CAAC,EAAE,CAAC,OAAO;IAChD,MAAM,YAAY,aAAa,UAAU,IAAI,EAAE;IAE/C,IAAI,UAAU,MAAM,GAAG,GAAG;QACxB,MAAM,gBAAgB,EAAE;QAExB,KAAK,MAAM,YAAY,UAAW;YAChC,MAAM,eAAe,MAAM,gBAAgB;YAC3C,cAAc,IAAI,CAAC;YAEnB,SAAS,IAAI,CAAC;gBACZ,MAAM;gBACN,SAAS;gBACT,YAAY;oBAAC;iBAAS;YACxB;YAEA,SAAS,IAAI,CAAC;gBACZ,MAAM;gBACN,SAAS,aAAa,MAAM;gBAC5B,cAAc,SAAS,EAAE;YAC3B;QACF;QAEA,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACpD,OAAO;YACP;QACF;QAEA,OAAO;YACL,OAAO,SAAS,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,IAAI;YAC9C;YACA;QACF;IACF;IAEA,OAAO;QACL,OAAO,aAAa,OAAO,IAAI;QAC/B,WAAW,EAAE;QACb,eAAe,EAAE;IACnB;AACF","debugId":null}},
    {"offset": {"line": 302, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/adity/mcp-project/Nextjs-MCP-Chat/app/api/chat/route.ts"],"sourcesContent":["// import { NextRequest, NextResponse } from \"next/server\";\r\n// import { OpenAI } from \"openai\";\r\n// import { OpenAIToolSet } from \"composio-core\";\r\n\r\n// const toolset = new OpenAIToolSet();\r\n// const client = new OpenAI({\r\n//   apiKey: process.env.OPENAI_API_KEY,\r\n// });\r\n\r\n// export async function POST(req: NextRequest) {\r\n//   const { messages } = await req.json();\r\n\r\n//   const userQuery = messages[messages.length - 1]?.content;\r\n//   if (!userQuery) {\r\n//     return NextResponse.json(\r\n//       { error: \"No user query found in request\" },\r\n//       { status: 400 },\r\n//     );\r\n//   }\r\n\r\n//   try {\r\n//     const tools = await toolset.getTools({\r\n//       // You can directly specify multiple apps like so, but doing so might\r\n//       // result in > 128 tools, but openai limits on 128 tools\r\n//       // apps: [\"gmail\", \"slack\"],\r\n//       //\r\n//       // Or, single apps like so:\r\n//       // apps: [\"gmail\"],\r\n//       //\r\n//       // Or, directly specifying actions like so:\r\n//       // actions: [\"GMAIL_SEND_EMAIL\", \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL\"],\r\n\r\n//       // Gmail and Linear does not cross the tool limit of 128 when combined\r\n//       // together as well\r\n//       apps: [\"gmail\", \"linear\"],\r\n//     });\r\n//     console.log(\r\n//       `[DEBUG]: Tools length: ${tools.length}. Errors out if greater than 128`,\r\n//     );\r\n\r\n//     const fullMessages = [\r\n//       {\r\n//         role: \"system\",\r\n//         content: \"You are a helpful assistant that can use tools.\",\r\n//       },\r\n//       ...messages,\r\n//     ];\r\n\r\n//     const response = await client.chat.completions.create({\r\n//       model: \"gpt-4o-mini\",\r\n//       messages: fullMessages,\r\n//       tools,\r\n//       // tool_choice: \"auto\",\r\n//     });\r\n\r\n//     const aiMessage = response.choices[0].message;\r\n//     const toolCalls = aiMessage.tool_calls || [];\r\n\r\n//     if (toolCalls.length > 0) {\r\n//       const toolResponses = [];\r\n\r\n//       for (const toolCall of toolCalls) {\r\n//         const res = await toolset.executeToolCall(toolCall);\r\n//         toolResponses.push(res);\r\n//         console.log(\"[DEBUG]: Executed tool call:\", res);\r\n//       }\r\n\r\n//       return NextResponse.json({\r\n//         role: \"assistant\",\r\n//         content: \"Successfully executed tool call(s) ðŸŽ‰ðŸŽ‰\",\r\n//         toolResponses,\r\n//       });\r\n//     }\r\n\r\n//     return NextResponse.json({\r\n//       role: \"assistant\",\r\n//       content: aiMessage.content || \"Sorry... got no response from the server\",\r\n//     });\r\n//   } catch (err) {\r\n//     console.error(err);\r\n//     return NextResponse.json(\r\n//       { error: \"Something went wrong!\" },\r\n//       { status: 500 },\r\n//     );\r\n//   }\r\n// }\r\n\r\n// ------ For Local Server MCP connection ------\r\nimport { NextRequest, NextResponse } from \"next/server\";\r\nimport { initMCP, processQuery } from \"@/lib/mcp-client\";\r\n\r\nconst SERVER_PATH = \"C:/Users/adity/mcp-project/chat-mcp-server/custom-fs-mcp-server/build/index.js\";\r\n\r\nexport async function POST(req: NextRequest) {\r\n  const { messages } = await req.json();\r\n  const userQuery = messages[messages.length - 1]?.content;\r\n\r\n  if (!userQuery) {\r\n    return NextResponse.json({ error: \"No query provided\" }, { status: 400 });\r\n  }\r\n\r\n  try {\r\n    await initMCP(SERVER_PATH);\r\n\r\n    const { reply, toolCalls, toolResponses } = await processQuery(messages);\r\n\r\n    if (toolCalls.length > 0) {\r\n      return NextResponse.json({\r\n        role: \"assistant\",\r\n        content: \"Successfully executed tool call(s) ðŸŽ‰ðŸŽ‰\",\r\n        toolResponses,\r\n      });\r\n    }\r\n\r\n    return NextResponse.json({\r\n      role: \"assistant\",\r\n      content: reply,\r\n    });\r\n  } catch (err) {\r\n    console.error(\"[MCP Error]\", err);\r\n    return NextResponse.json(\r\n      { error: \"Something went wrong\" },\r\n      { status: 500 },\r\n    );\r\n  }\r\n}"],"names":[],"mappings":"AAAA,2DAA2D;AAC3D,mCAAmC;AACnC,iDAAiD;AAEjD,uCAAuC;AACvC,8BAA8B;AAC9B,wCAAwC;AACxC,MAAM;AAEN,iDAAiD;AACjD,2CAA2C;AAE3C,8DAA8D;AAC9D,sBAAsB;AACtB,gCAAgC;AAChC,qDAAqD;AACrD,yBAAyB;AACzB,SAAS;AACT,MAAM;AAEN,UAAU;AACV,6CAA6C;AAC7C,8EAA8E;AAC9E,iEAAiE;AACjE,qCAAqC;AACrC,WAAW;AACX,oCAAoC;AACpC,4BAA4B;AAC5B,WAAW;AACX,oDAAoD;AACpD,sFAAsF;AAEtF,+EAA+E;AAC/E,4BAA4B;AAC5B,mCAAmC;AACnC,UAAU;AACV,mBAAmB;AACnB,kFAAkF;AAClF,SAAS;AAET,6BAA6B;AAC7B,UAAU;AACV,0BAA0B;AAC1B,sEAAsE;AACtE,WAAW;AACX,qBAAqB;AACrB,SAAS;AAET,8DAA8D;AAC9D,8BAA8B;AAC9B,gCAAgC;AAChC,eAAe;AACf,gCAAgC;AAChC,UAAU;AAEV,qDAAqD;AACrD,oDAAoD;AAEpD,kCAAkC;AAClC,kCAAkC;AAElC,4CAA4C;AAC5C,+DAA+D;AAC/D,mCAAmC;AACnC,4DAA4D;AAC5D,UAAU;AAEV,mCAAmC;AACnC,6BAA6B;AAC7B,8DAA8D;AAC9D,yBAAyB;AACzB,YAAY;AACZ,QAAQ;AAER,iCAAiC;AACjC,2BAA2B;AAC3B,kFAAkF;AAClF,UAAU;AACV,oBAAoB;AACpB,0BAA0B;AAC1B,gCAAgC;AAChC,4CAA4C;AAC5C,yBAAyB;AACzB,SAAS;AACT,MAAM;AACN,IAAI;AAEJ,gDAAgD;;;;AAChD;AACA;;;AAEA,MAAM,cAAc;AAEb,eAAe,KAAK,GAAgB;IACzC,MAAM,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,IAAI;IACnC,MAAM,YAAY,QAAQ,CAAC,SAAS,MAAM,GAAG,EAAE,EAAE;IAEjD,IAAI,CAAC,WAAW;QACd,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAoB,GAAG;YAAE,QAAQ;QAAI;IACzE;IAEA,IAAI;QACF,MAAM,CAAA,GAAA,+HAAA,CAAA,UAAO,AAAD,EAAE;QAEd,MAAM,EAAE,KAAK,EAAE,SAAS,EAAE,aAAa,EAAE,GAAG,MAAM,CAAA,GAAA,+HAAA,CAAA,eAAY,AAAD,EAAE;QAE/D,IAAI,UAAU,MAAM,GAAG,GAAG;YACxB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;gBACvB,MAAM;gBACN,SAAS;gBACT;YACF;QACF;QAEA,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YACvB,MAAM;YACN,SAAS;QACX;IACF,EAAE,OAAO,KAAK;QACZ,QAAQ,KAAK,CAAC,eAAe;QAC7B,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAuB,GAChC;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}